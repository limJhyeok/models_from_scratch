{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my github: https://github.com/withAnewWorld/models_from_scratch\n",
    "# my blog\n",
    "# https://self-deeplearning.blogspot.com/\n",
    "# https://self-deeplearning.tistory.com/\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref\n",
    "paper: https://arxiv.org/abs/1409.4842 <br>\n",
    "ref(how to make GoogLeNet with PyTorch, youtuber: Aladdin Persson): <br>\n",
    "https://www.youtube.com/watch?v=uQc4Fs7yx5I&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=18 <br>\n",
    "(GoogLeNet 설명(한글)) <br>\n",
    "https://phil-baek.tistory.com/entry/3-GoogLeNet-Going-deeper-with-convolutions-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0 <br>\n",
    "(Auxiliary classifiers) <br>\n",
    "http://datacrew.tech/inception-v1-2014/ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "1. GoogLeNet 의의 & 탄생배경\n",
    "2. GoogLeNet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiRm_GtIYE5n"
   },
   "source": [
    "## GoogLeNet(InceptionNet)\n",
    "\"We need to go deeper\" (2010, inception) <br>\n",
    "의의: 효율적이면서 성능이 뛰어난 deep learning model 개발 시발점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koC0th3aZubh"
   },
   "source": [
    "탄생배경 <br>\n",
    "conv net의 성능을 올리는 일반적인 방법은 2가지가 있습니다. <br>\n",
    "> 1) increase the depth(level) <br>\n",
    "> 2) increase the width(각 level의 unit) <br>\n",
    "\n",
    "해당 방법들의 문제점 <br>\n",
    "> 1) overfitting(과적합) <br>\n",
    "> 2) 급격히 증가하는 computational resources <br>\n",
    "* overfitting: model이 train data에 과도하게 최적화되어 test data에 대해서 낮은 성능을 보이는 case <br>\n",
    "사람에게 비유하면 한 학생이 책에 있는 문제를 모두 외워서 책에 있는 문제는 잘 풀지만 처음 보는 문제(시험)에서는 낮은 점수를 받는 것과 비슷한 경우<br>\n",
    "(적절한 학습이 이루어지지 않았다는 반증)\n",
    "\n",
    "위의 문제를 근본적으로 풀기 위해서는 fully connected layer에서 sparsely connected layer로 변환해야 합니다. <br>\n",
    "하지만, computer 구조상 non-uniform sparsely data를 다루는 데에 비효율적이므로 이를 적용하기 어렵습니다. <br>\n",
    "\n",
    "sparse 매트릭스를 clustering(묶어서), 상대적으로 dense한 submatricies로 변환하여 계산하는 것이 sparse matrix 연산 논문에서 좋은 성능을 보이는 것이 입증되어왔습니다. <br>\n",
    "\n",
    "해당 아이디어를 따와서 conv net에 적용 <br>\n",
    "\n",
    "ref: https://phil-baek.tistory.com/entry/3-GoogLeNet-Going-deeper-with-convolutions-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBGbXV%2FbtqSDvAa5N1%2FbVaRLW8gpuO5ymxKZfHkbK%2Fimg.png\" height = 500>\n",
    "</p>\n",
    "\n",
    "<div align=\"center\">  왼쪽: sparse matrix, 오른쪽 dense matrix</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://blog.kakaocdn.net/dn/Iq9NO/btqyPWk5PBX/K2JicGjIjj5w0eFIbhx4bK/img.png\" height = 500>\n",
    "</p>\n",
    "<div align = center> GooglLeNet architecture</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_rdfx26chwp"
   },
   "source": [
    "GoogLeNet의 전체 구조는 inception module이라 불리는 block이 반복되어 layer를 쌓아나가는 구조입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/withAnewWorld/models_from_scratch/main/pic/inception_module.png\" height = 250>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoatvvaAdMvz"
   },
   "source": [
    "그러면 pseudo code로 Inception module을 만들어 보겠습니다. <br>\n",
    "```python\n",
    "class InceptionModule(nn.Module):\n",
    "  def __init__(self):\n",
    "    self.conv1 = nn.Conv2d(in_channels,\n",
    "                          out_channels,\n",
    "                          kernel_size = (1, 1),\n",
    "                          stride = 1) # 가장 왼쪽 conv net\n",
    "\n",
    "    self.conv_3x3 = nn.Sequential(nn.Conv2d(kernel_size = (1, 1),\n",
    "                                            stride = 1),\n",
    "                                  nn.Conv2d(kernel_size = (3, 3),\n",
    "                                            stride = 1,\n",
    "                                            padding = 1))\n",
    "    \n",
    "    self.conv_5x5 = nn.Sequential(nn.Conv2d(kernel_size = (1, 1),\n",
    "                                            stride= 1,),\n",
    "                                  nn.Conv2d(kernel_size = (5, 5),\n",
    "                                            stride =1,\n",
    "                                            padding = 2)\n",
    "\n",
    "    self.projection = nn.Sequential(nn.MaxPool2d(),\n",
    "                                    nn.Conv2d(in_channels,\n",
    "                                              out_channels,\n",
    "                                              kernel_size = (1, 1),\n",
    "                                              stride = 1) # 가장 오른쪽 layer\n",
    "  def forward(self, x):\n",
    "    out1 = self.conv1(x)\n",
    "    out2 = self.conv_3x3(x)\n",
    "    ...\n",
    "    return concat(outs, dim = filter)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqKBtjvGkkY9"
   },
   "source": [
    "위의 GoogLeNet architecture image를 자세히 보시면 중간에 튀어나온 module을 확인하실 수 있습니다. <br>\n",
    "해당 module은 깊이가 매우 깊어지는 architecture의 경우 gradient vanishing/exploding이 발생하여 model의 성능을 떨어뜨릴 수 있기 때문에 중간마다 역전파를 계속 전달해주는 역할을 합니다. <br>\n",
    "단, test 시에는 해당 모듈을 사용하지 않고 output을 도출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/withAnewWorld/models_from_scratch/main/pic/auxiliary_classifier.png\" height = 300>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Yx4NA6QllHH"
   },
   "source": [
    "```python\n",
    "# pseudo code\n",
    "class AuxiliaryClassifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    self.auxiliary_classifier = nn.Sequential(nn.AvgPool2d(),\n",
    "                                            nn.Conv2d(kernel_size = (1,1),\n",
    "                                                      stride = 1),\n",
    "                                            nn.Linear(),\n",
    "                                            nn.Linear(),\n",
    "                                            nn.Softmax())\n",
    "\n",
    "  def forward(self, x)\n",
    "    return self.auxiliary_classifier(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/withAnewWorld/models_from_scratch/main/pic/GoogLeNet.png\" height = 450>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7vRF7LAd_nZ"
   },
   "source": [
    "```python\n",
    "#pseudo code\n",
    "class GoogLeNet(nn.Module):\n",
    "  def __init__():\n",
    "    self.conv = nn.Conv2d()\n",
    "    self.pool = nn.MaxPool2d()\n",
    "    self.inception_3a = inception_module()\n",
    "    ...\n",
    "    self.classifier_1 = auxiliary_classifier()\n",
    "    self.classifier_2 = auxiliary_classifier()\n",
    "    ...\n",
    "\n",
    "    self.fc = nn.Sequential(nn.AvgPool2d(),\n",
    "                            nn.DropOut(),\n",
    "                            nn.Flatten(),\n",
    "                            nn.Linear(),\n",
    "                            nn.Softmax())\n",
    "\n",
    "  def forward(self, x)\n",
    "    out_1 = self.classifier_1(blocks(x))\n",
    "    out_2 = self.classifier_2(blocks(x))\n",
    "    out_3 = self.fc(blocks(x))\n",
    "    \n",
    "    return out_1, out_2, out_3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIw7HZx-ukap"
   },
   "source": [
    "## Let's make GoogLeNet\n",
    "순서 <br>\n",
    "1) inception module <br>\n",
    "2) auxiliary_classifier <br>\n",
    "3) GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3tl7T8yVBMA5"
   },
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "  def __init__(self, \n",
    "               in_channels, \n",
    "               reduce_3_out, \n",
    "               reduce_5_out, \n",
    "               conv_1_out, \n",
    "               conv_3_out, \n",
    "               conv_5_out, \n",
    "               proj_out):\n",
    "    super(InceptionModule, self).__init__()\n",
    "    self.reduce_3 = nn.Conv2d(in_channels = in_channels,\n",
    "                         out_channels = reduce_3_out,\n",
    "                         kernel_size = (1, 1),\n",
    "                         stride = 1)\n",
    "    self.conv_3 = nn.Conv2d(in_channels = reduce_3_out,\n",
    "                       out_channels = conv_3_out,\n",
    "                       kernel_size = (3, 3),\n",
    "                       stride = 1,\n",
    "                       padding = 1)\n",
    "    \n",
    "    self.reduce_5 = nn.Conv2d(in_channels = in_channels,\n",
    "                         out_channels = reduce_5_out,\n",
    "                         kernel_size = (1, 1),\n",
    "                         stride = 1)\n",
    "    self.conv_5 = nn.Conv2d(in_channels = reduce_5_out,\n",
    "                       out_channels = conv_5_out,\n",
    "                       kernel_size =(5, 5),\n",
    "                       stride = 1,\n",
    "                       padding = 2)\n",
    "    \n",
    "    self.pool = nn.MaxPool2d(kernel_size = (3, 3),\n",
    "                             stride = (1, 1),\n",
    "                             padding = 1)\n",
    "    \n",
    "    self.proj = nn.Conv2d(in_channels = in_channels,\n",
    "                            out_channels = proj_out,\n",
    "                            kernel_size = (1, 1),\n",
    "                            stride = 1)\n",
    "    self.conv_1 = nn.Conv2d(in_channels = in_channels,\n",
    "                          out_channels = conv_1_out,\n",
    "                          kernel_size = (1, 1),\n",
    "                          stride = 1)\n",
    "                            \n",
    "  def forward(self, x):\n",
    "    '''\n",
    "    inputs:\n",
    "      - previous layer(Tensor[N, in_channels, H, W])\n",
    "    returns:\n",
    "      - filter concat(Tensor[N, concat(channels), H, W])\n",
    "    * channels: (conv_1_out, conv_3_out, conv_5_out, proj_out)\n",
    "    '''\n",
    "    output_1 = self.conv_1(x)\n",
    "    output_2 = self.conv_3(self.reduce_3(x))\n",
    "    output_3 = self.conv_5(self.reduce_5(x))\n",
    "    output_4 = self.proj(self.pool(x))\n",
    "\n",
    "    return torch.cat((output_1, output_2, output_3, output_4), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z6NMqR82Fvd9"
   },
   "outputs": [],
   "source": [
    "X = torch.randn(1, 192, 28, 28)\n",
    "model = InceptionModule(in_channels = 192,\n",
    "                         reduce_3_out = 96,\n",
    "                         reduce_5_out = 16,\n",
    "                         conv_1_out = 64,\n",
    "                         conv_3_out = 128,\n",
    "                         conv_5_out = 32,\n",
    "                         proj_out = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uArhirvGILDx",
    "outputId": "e51a9015-b424-449e-902e-01288c71bf9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(X)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VMf0VQdlm9kk"
   },
   "outputs": [],
   "source": [
    "# after 4a, 4d\n",
    "# after avg pool2d 4a -> (4, 4, 512), 4d -> (4, 4, 528) from paper page 6 bottom line \n",
    "# ref(stride, out_channels, ..., etc): http://datacrew.tech/inception-v1-2014/\n",
    "class AuxiliaryClassifier(nn.Module): \n",
    "  def __init__(self, in_channels, num_classes):\n",
    "    super(AuxiliaryClassifier, self).__init__()\n",
    "    self.auxiliary_classifier = nn.Sequential(nn.AvgPool2d(kernel_size = (5, 5),\n",
    "                                                           stride = 3),\n",
    "                                            nn.Conv2d(in_channels= in_channels,\n",
    "                                                      out_channels = 128,\n",
    "                                                      kernel_size = (1,1),\n",
    "                                                      stride = 1),\n",
    "                                            nn.Flatten(),\n",
    "                                            nn.Linear(in_features = 128 * 4 * 4,\n",
    "                                                      out_features = 1024),\n",
    "                                            nn.Linear(in_features = 1024, \n",
    "                                                      out_features = num_classes),\n",
    "                                            nn.Softmax(dim = -1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.auxiliary_classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3V4CJmbTBDOM"
   },
   "outputs": [],
   "source": [
    "# batch norm, activation fn, ... 생략\n",
    "class GoogLeNet(nn.Module):\n",
    "  def __init__(self, img_channels = 3, num_classes = 1000):\n",
    "    super(GoogLeNet, self).__init__()\n",
    "    self.prev_inception = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = img_channels,\n",
    "                  out_channels = 64,\n",
    "                  kernel_size = (7, 7),\n",
    "                  stride = 2,\n",
    "                  padding = 3),\n",
    "        nn.MaxPool2d(kernel_size = (3, 3),\n",
    "                     stride = 2,\n",
    "                     padding = 1),\n",
    "        nn.Conv2d(in_channels = 64,\n",
    "                  out_channels = 192,\n",
    "                  kernel_size =(3, 3),\n",
    "                  stride = 1,\n",
    "                  padding = 1),\n",
    "        nn.MaxPool2d(kernel_size = (3, 3),\n",
    "                     stride= 2,\n",
    "                     padding = 1)\n",
    "    )\n",
    "    self.inception_3a = InceptionModule(in_channels = 192,\n",
    "                         reduce_3_out = 96,\n",
    "                         reduce_5_out = 16,\n",
    "                         conv_1_out = 64,\n",
    "                         conv_3_out = 128,\n",
    "                         conv_5_out = 32,\n",
    "                         proj_out = 32)\n",
    "    self.inception_3b = InceptionModule(in_channels = 256,\n",
    "                         reduce_3_out = 128,\n",
    "                         reduce_5_out = 32,\n",
    "                         conv_1_out = 128,\n",
    "                         conv_3_out = 192,\n",
    "                         conv_5_out = 96,\n",
    "                         proj_out = 64)\n",
    "    self.pool_3 = nn.MaxPool2d(kernel_size = (3, 3),\n",
    "                             stride = 2,\n",
    "                             padding = 1)\n",
    "    \n",
    "    self.inception_4a = InceptionModule(in_channels = 480,\n",
    "                         reduce_3_out = 96,\n",
    "                         reduce_5_out = 16,\n",
    "                         conv_1_out = 192,\n",
    "                         conv_3_out = 208,\n",
    "                         conv_5_out = 48,\n",
    "                         proj_out = 64)\n",
    "    self.classifier_1 =  AuxiliaryClassifier(in_channels = 512,\n",
    "                                              num_classes = num_classes)\n",
    "\n",
    "    self.inception_4b = InceptionModule(in_channels = 512,\n",
    "                         reduce_3_out = 112,\n",
    "                         reduce_5_out = 24,\n",
    "                         conv_1_out = 160,\n",
    "                         conv_3_out = 224,\n",
    "                         conv_5_out = 64,\n",
    "                         proj_out = 64)\n",
    "    self.inception_4c = InceptionModule(in_channels = 512,\n",
    "                         reduce_3_out = 128,\n",
    "                         reduce_5_out = 24,\n",
    "                         conv_1_out = 128,\n",
    "                         conv_3_out = 256,\n",
    "                         conv_5_out = 64,\n",
    "                         proj_out = 64)\n",
    "    self.inception_4d = InceptionModule(in_channels = 512,\n",
    "                         reduce_3_out = 144,\n",
    "                         reduce_5_out = 32,\n",
    "                         conv_1_out = 112,\n",
    "                         conv_3_out = 288,\n",
    "                         conv_5_out = 64,\n",
    "                         proj_out = 64)\n",
    "    self.classifier_2 =  AuxiliaryClassifier(in_channels = 528,\n",
    "                                              num_classes = num_classes)\n",
    "\n",
    "    self.inception_4e = InceptionModule(in_channels = 528,\n",
    "                         reduce_3_out = 160,\n",
    "                         reduce_5_out = 32,\n",
    "                         conv_1_out = 256,\n",
    "                         conv_3_out = 320,\n",
    "                         conv_5_out = 128,\n",
    "                         proj_out = 128)\n",
    "    self.pool_4 = nn.MaxPool2d(kernel_size = (3, 3),\n",
    "                             stride = 2,\n",
    "                             padding = 1)\n",
    "    \n",
    "    self.inception_5a = InceptionModule(in_channels = 832,\n",
    "                         reduce_3_out = 160,\n",
    "                         reduce_5_out = 32,\n",
    "                         conv_1_out = 256,\n",
    "                         conv_3_out = 320,\n",
    "                         conv_5_out = 128,\n",
    "                         proj_out = 128)\n",
    "    self.inception_5b = InceptionModule(in_channels = 832,\n",
    "                         reduce_3_out = 192,\n",
    "                         reduce_5_out = 48,\n",
    "                         conv_1_out = 384,\n",
    "                         conv_3_out = 384,\n",
    "                         conv_5_out = 128,\n",
    "                         proj_out = 128)\n",
    "    self.pool_5 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "    self.drop = nn.Dropout(p=0.4)\n",
    "    self.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features = 1024,\n",
    "                  out_features = num_classes),\n",
    "        nn.Softmax(dim = -1)\n",
    "\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = self.prev_inception(x)\n",
    "    print(x.size())\n",
    "    x = self.inception_3a(x)\n",
    "    print(x.size())\n",
    "    x = self.inception_3b(x)\n",
    "    print(x.size())\n",
    "    x = self.pool_3(x)\n",
    "    \n",
    "    x = self.inception_4a(x)\n",
    "    print(x.size())\n",
    "    out_1 = self.classifier_1(x)\n",
    "    \n",
    "    x = self.inception_4b(x)\n",
    "    print(x.size())\n",
    "    x = self.inception_4c(x)\n",
    "    print(x.size())\n",
    "    x = self.inception_4d(x)\n",
    "    print(x.size())\n",
    "    out_2 = self.classifier_2(x)\n",
    "\n",
    "    x = self.inception_4e(x)\n",
    "    print(x.size())\n",
    "    x = self.pool_4(x)\n",
    "\n",
    "    x = self.inception_5a(x)\n",
    "    print(x.size())\n",
    "    x = self.inception_5b(x)\n",
    "    print(x.size())\n",
    "    x = self.pool_5(x)\n",
    "    x = self.drop(x)\n",
    "    x = self.fc(x)\n",
    "    print(x.size())\n",
    "    return out_1, out_2, x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "usX6ugkwXER2"
   },
   "outputs": [],
   "source": [
    "model = GoogLeNet()\n",
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGgNo9gpXIRM",
    "outputId": "fde80ebf-f0ad-4b03-a583-1c9351696367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 192, 28, 28])\n",
      "torch.Size([1, 256, 28, 28])\n",
      "torch.Size([1, 480, 28, 28])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 512, 14, 14])\n",
      "torch.Size([1, 528, 14, 14])\n",
      "torch.Size([1, 832, 14, 14])\n",
      "torch.Size([1, 832, 7, 7])\n",
      "torch.Size([1, 1024, 7, 7])\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "out_1, out_2, out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o9-jCpn6rhOD",
    "outputId": "eb1df826-e19e-421e-ed3d-78617b506780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_1 size:  torch.Size([1, 1000])\n",
      "out_2 size:  torch.Size([1, 1000])\n",
      "out size:  torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print('out_1 size: ', out_1.size()) \n",
    "print('out_2 size: ', out_2.size())\n",
    "print('out size: ', out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quQ0UStIXmMm",
    "outputId": "c55d7bd3-b352-4732-fd0f-b0cf8d871b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13374120\n"
     ]
    }
   ],
   "source": [
    "# model parameter 개수\n",
    "count = 0\n",
    "for param in model.parameters():\n",
    "  count += param.numel()\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GoogLeNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
